{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:19:45.119810Z",
     "iopub.status.busy": "2025-04-25T08:19:45.119479Z",
     "iopub.status.idle": "2025-04-25T08:19:45.331641Z",
     "shell.execute_reply": "2025-04-25T08:19:45.330616Z",
     "shell.execute_reply.started": "2025-04-25T08:19:45.119788Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ibrah\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ibrah\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: sklearn-pandas in c:\\users\\ibrah\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.0)\n",
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-3.0.0-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting catboost\n",
      "  Using cached catboost-1.2.8-cp313-cp313-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting optuna\n",
      "  Using cached optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ibrah\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ibrah\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ibrah\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scikit-learn>=0.23.0 in c:\\users\\ibrah\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sklearn-pandas) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.5.1 in c:\\users\\ibrah\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sklearn-pandas) (1.15.2)\n",
      "Collecting graphviz (from catboost)\n",
      "  Using cached graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting matplotlib (from catboost)\n",
      "  Using cached matplotlib-3.10.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting plotly (from catboost)\n",
      "  Using cached plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six in c:\\users\\ibrah\\appdata\\roaming\\python\\python313\\site-packages (from catboost) (1.17.0)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Using cached alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ibrah\\appdata\\roaming\\python\\python313\\site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Using cached sqlalchemy-2.0.40-cp313-cp313-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting tqdm (from optuna)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests (from kagglehub)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.12 (from alembic>=1.5.0->optuna)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ibrah\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn>=0.23.0->sklearn-pandas) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ibrah\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn>=0.23.0->sklearn-pandas) (3.6.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Using cached greenlet-3.2.1-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ibrah\\appdata\\roaming\\python\\python313\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->catboost)\n",
      "  Using cached contourpy-1.3.2-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->catboost)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->catboost)\n",
      "  Using cached fonttools-4.57.0-cp313-cp313-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->catboost)\n",
      "  Using cached kiwisolver-1.4.8-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib->catboost)\n",
      "  Using cached pillow-11.2.1-cp313-cp313-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->catboost)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly->catboost)\n",
      "  Using cached narwhals-1.36.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->kagglehub)\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->kagglehub)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->kagglehub)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->kagglehub)\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting MarkupSafe>=0.9.2 (from Mako->alembic>=1.5.0->optuna)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "Using cached xgboost-3.0.0-py3-none-win_amd64.whl (150.0 MB)\n",
      "Using cached catboost-1.2.8-cp313-cp313-win_amd64.whl (102.4 MB)\n",
      "Using cached optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Using cached alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Using cached sqlalchemy-2.0.40-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Using cached matplotlib-3.10.1-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "Using cached plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Using cached contourpy-1.3.2-cp313-cp313-win_amd64.whl (223 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.2 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 8.7 MB/s eta 0:00:00\n",
      "Using cached greenlet-3.2.1-cp313-cp313-win_amd64.whl (295 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached kiwisolver-1.4.8-cp313-cp313-win_amd64.whl (71 kB)\n",
      "Using cached narwhals-1.36.0-py3-none-any.whl (331 kB)\n",
      "Downloading pillow-11.2.1-cp313-cp313-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.6/2.7 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 11.9 MB/s eta 0:00:00\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, PyYAML, pyparsing, pillow, narwhals, MarkupSafe, kiwisolver, idna, greenlet, graphviz, fonttools, cycler, contourpy, colorlog, charset-normalizer, certifi, xgboost, sqlalchemy, requests, plotly, matplotlib, Mako, lightgbm, kagglehub, catboost, alembic, optuna\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\Users\\\\Ibrah\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\PIL\\\\FpxImagePlugin.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, StandardScaler\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VotingClassifier\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy sklearn-pandas lightgbm xgboost catboost optuna kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "\n",
    "# Download latest version\n",
    "# === Download Dataset ===\n",
    "path = kagglehub.dataset_download(\"thedevastator/higher-education-predictors-of-student-retention\")\n",
    "csv_file = [f for f in os.listdir(path) if f.endswith(\".csv\")][0]\n",
    "df = pd.read_csv(os.path.join(path, csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:20:00.422177Z",
     "iopub.status.busy": "2025-04-25T08:20:00.421888Z",
     "iopub.status.idle": "2025-04-25T08:20:00.440500Z",
     "shell.execute_reply": "2025-04-25T08:20:00.439420Z",
     "shell.execute_reply.started": "2025-04-25T08:20:00.422157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Features and labels\n",
    "X = df.drop(columns=['Target'])\n",
    "y = LabelEncoder().fit_transform(df['Target'])  # target must be numerical\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:20:23.917906Z",
     "iopub.status.busy": "2025-04-25T08:20:23.917585Z",
     "iopub.status.idle": "2025-04-25T08:23:36.022469Z",
     "shell.execute_reply": "2025-04-25T08:23:36.021582Z",
     "shell.execute_reply.started": "2025-04-25T08:20:23.917884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 08:20:23,924] A new study created in memory with name: no-name-a5e03301-b7a1-44cf-adab-8510f5aa8c65\n",
      "[I 2025-04-25 08:20:29,794] Trial 0 finished with value: 0.707263545121316 and parameters: {'max_depth': 12, 'learning_rate': 0.05171451071010541, 'n_estimators': 473, 'reg_alpha': 1.4583125834784127, 'reg_lambda': 0.6775343638665765, 'subsample': 0.73796781078786, 'colsample_bytree': 0.6745349661167812, 'num_leaves': 99}. Best is trial 0 with value: 0.707263545121316.\n",
      "[I 2025-04-25 08:20:31,851] Trial 1 finished with value: 0.7020652635075727 and parameters: {'max_depth': 4, 'learning_rate': 0.06556035065753119, 'n_estimators': 617, 'reg_alpha': 4.229671821639606, 'reg_lambda': 4.049574073853709, 'subsample': 0.6455297251477711, 'colsample_bytree': 0.6478339052826397, 'num_leaves': 87}. Best is trial 0 with value: 0.707263545121316.\n",
      "[I 2025-04-25 08:20:35,957] Trial 2 finished with value: 0.708563269859439 and parameters: {'max_depth': 11, 'learning_rate': 0.0502533979015717, 'n_estimators': 1173, 'reg_alpha': 3.4363211186127645, 'reg_lambda': 0.33150300209010164, 'subsample': 0.5671971341101949, 'colsample_bytree': 0.7628768776670387, 'num_leaves': 58}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:20:40,522] Trial 3 finished with value: 0.701807651479529 and parameters: {'max_depth': 6, 'learning_rate': 0.06163315802816722, 'n_estimators': 1136, 'reg_alpha': 4.0336401958380765, 'reg_lambda': 0.6432802620240674, 'subsample': 0.779065087307322, 'colsample_bytree': 0.4666169220277217, 'num_leaves': 39}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:20:45,317] Trial 4 finished with value: 0.6913172912568665 and parameters: {'max_depth': 8, 'learning_rate': 0.18569209017444324, 'n_estimators': 936, 'reg_alpha': 0.182655240421693, 'reg_lambda': 1.8054318974466361, 'subsample': 0.9906602838339387, 'colsample_bytree': 0.7755723277746627, 'num_leaves': 39}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:20:52,784] Trial 5 finished with value: 0.7058842747293198 and parameters: {'max_depth': 4, 'learning_rate': 0.04006201957675787, 'n_estimators': 1367, 'reg_alpha': 1.8141290954757505, 'reg_lambda': 4.008617551330571, 'subsample': 0.906891025880098, 'colsample_bytree': 0.4571199078711221, 'num_leaves': 92}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:03,156] Trial 6 finished with value: 0.6962334453993827 and parameters: {'max_depth': 6, 'learning_rate': 0.036248532305907265, 'n_estimators': 1010, 'reg_alpha': 0.1210372431006318, 'reg_lambda': 1.3793514539626295, 'subsample': 0.6656447379296414, 'colsample_bytree': 0.9902165731777101, 'num_leaves': 99}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:05,128] Trial 7 finished with value: 0.6969992085135566 and parameters: {'max_depth': 7, 'learning_rate': 0.0823789278379815, 'n_estimators': 280, 'reg_alpha': 4.842129152154598, 'reg_lambda': 4.405970377673682, 'subsample': 0.9644198684077734, 'colsample_bytree': 0.5016145354004804, 'num_leaves': 73}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:08,255] Trial 8 finished with value: 0.7012479897844609 and parameters: {'max_depth': 12, 'learning_rate': 0.17581414061900544, 'n_estimators': 1226, 'reg_alpha': 3.51316663657836, 'reg_lambda': 4.461737962174678, 'subsample': 0.7936653338181734, 'colsample_bytree': 0.5926458929817071, 'num_leaves': 70}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:11,275] Trial 9 finished with value: 0.7067551771830308 and parameters: {'max_depth': 3, 'learning_rate': 0.025917307467199308, 'n_estimators': 834, 'reg_alpha': 2.662273096749103, 'reg_lambda': 1.6689001191837172, 'subsample': 0.8827819756455797, 'colsample_bytree': 0.8788013427709758, 'num_leaves': 66}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:14,175] Trial 10 finished with value: 0.7072131921778076 and parameters: {'max_depth': 10, 'learning_rate': 0.12082266722716592, 'n_estimators': 1475, 'reg_alpha': 2.9962959811678864, 'reg_lambda': 2.965354842877232, 'subsample': 0.4395356400466994, 'colsample_bytree': 0.7727432110746822, 'num_leaves': 20}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:16,873] Trial 11 finished with value: 0.7042403599544351 and parameters: {'max_depth': 12, 'learning_rate': 0.11620046434949118, 'n_estimators': 515, 'reg_alpha': 1.6188256708397077, 'reg_lambda': 0.43903704299565427, 'subsample': 0.5426283587903522, 'colsample_bytree': 0.715254757734222, 'num_leaves': 50}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:18,023] Trial 12 finished with value: 0.6708010127564662 and parameters: {'max_depth': 10, 'learning_rate': 0.011176217719225667, 'n_estimators': 161, 'reg_alpha': 1.5351275456100542, 'reg_lambda': 0.04632680535300948, 'subsample': 0.5671977626407807, 'colsample_bytree': 0.8604974443308233, 'num_leaves': 15}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:21,282] Trial 13 finished with value: 0.7058336966199423 and parameters: {'max_depth': 10, 'learning_rate': 0.09353186657944415, 'n_estimators': 619, 'reg_alpha': 2.2117526473812488, 'reg_lambda': 1.0281033730491655, 'subsample': 0.4092390120679375, 'colsample_bytree': 0.6099626043556168, 'num_leaves': 81}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:24,020] Trial 14 finished with value: 0.6965394976124214 and parameters: {'max_depth': 11, 'learning_rate': 0.14729902235401948, 'n_estimators': 438, 'reg_alpha': 1.2656794028157492, 'reg_lambda': 2.467605795295172, 'subsample': 0.7624580812009489, 'colsample_bytree': 0.7179128502040131, 'num_leaves': 51}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:28,278] Trial 15 finished with value: 0.7010519595857211 and parameters: {'max_depth': 9, 'learning_rate': 0.05967747922965354, 'n_estimators': 344, 'reg_alpha': 0.7762367520848503, 'reg_lambda': 0.09125304688064306, 'subsample': 0.5754324325268638, 'colsample_bytree': 0.8657845532289521, 'num_leaves': 35}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:32,220] Trial 16 finished with value: 0.7022195689482307 and parameters: {'max_depth': 12, 'learning_rate': 0.08054184903104045, 'n_estimators': 722, 'reg_alpha': 3.4289498584379974, 'reg_lambda': 2.3646180866069404, 'subsample': 0.5000561891763877, 'colsample_bytree': 0.5512720154090921, 'num_leaves': 100}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:37,454] Trial 17 finished with value: 0.7022256757612423 and parameters: {'max_depth': 11, 'learning_rate': 0.04912327602513906, 'n_estimators': 1229, 'reg_alpha': 2.4310824402954374, 'reg_lambda': 0.8346049742924956, 'subsample': 0.6352335431305844, 'colsample_bytree': 0.7933774469456962, 'num_leaves': 60}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:53,649] Trial 18 finished with value: 0.7014430265899249 and parameters: {'max_depth': 9, 'learning_rate': 0.015700267996228097, 'n_estimators': 1045, 'reg_alpha': 0.7529060802921741, 'reg_lambda': 3.0116303001607085, 'subsample': 0.7323139622167159, 'colsample_bytree': 0.6681095309193456, 'num_leaves': 80}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:55,617] Trial 19 finished with value: 0.7039938610117894 and parameters: {'max_depth': 11, 'learning_rate': 0.13079577226654143, 'n_estimators': 849, 'reg_alpha': 3.1737939398867456, 'reg_lambda': 1.2350632012553366, 'subsample': 0.7022006530206983, 'colsample_bytree': 0.9627088851742471, 'num_leaves': 28}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:21:57,293] Trial 20 finished with value: 0.6992877363322423 and parameters: {'max_depth': 8, 'learning_rate': 0.09111936013981195, 'n_estimators': 162, 'reg_alpha': 3.9488873617665248, 'reg_lambda': 1.9680493907355359, 'subsample': 0.8234648040633104, 'colsample_bytree': 0.5318008078515635, 'num_leaves': 53}. Best is trial 2 with value: 0.708563269859439.\n",
      "[I 2025-04-25 08:22:00,287] Trial 21 finished with value: 0.7092509815747766 and parameters: {'max_depth': 10, 'learning_rate': 0.11519994600311825, 'n_estimators': 1451, 'reg_alpha': 2.906799453098461, 'reg_lambda': 3.160620033946314, 'subsample': 0.40915560861274625, 'colsample_bytree': 0.7727045520899417, 'num_leaves': 18}. Best is trial 21 with value: 0.7092509815747766.\n",
      "[I 2025-04-25 08:22:03,380] Trial 22 finished with value: 0.6993734220627043 and parameters: {'max_depth': 11, 'learning_rate': 0.15091091636449033, 'n_estimators': 1458, 'reg_alpha': 2.1480366373737834, 'reg_lambda': 3.3104355223586515, 'subsample': 0.4793882130976479, 'colsample_bytree': 0.7324584395155529, 'num_leaves': 27}. Best is trial 21 with value: 0.7092509815747766.\n",
      "[I 2025-04-25 08:22:06,958] Trial 23 finished with value: 0.7062865242530978 and parameters: {'max_depth': 9, 'learning_rate': 0.09890337731153756, 'n_estimators': 1227, 'reg_alpha': 2.76851155027541, 'reg_lambda': 3.3409484532167664, 'subsample': 0.4886737366233666, 'colsample_bytree': 0.796005181497289, 'num_leaves': 58}. Best is trial 21 with value: 0.7092509815747766.\n",
      "[I 2025-04-25 08:22:10,526] Trial 24 finished with value: 0.7013573452642529 and parameters: {'max_depth': 12, 'learning_rate': 0.06774079035801175, 'n_estimators': 1348, 'reg_alpha': 4.534867648183904, 'reg_lambda': 0.5376841305379099, 'subsample': 0.6027610904717076, 'colsample_bytree': 0.6683577725143691, 'num_leaves': 46}. Best is trial 21 with value: 0.7092509815747766.\n",
      "[I 2025-04-25 08:22:13,116] Trial 25 finished with value: 0.7020690381859324 and parameters: {'max_depth': 10, 'learning_rate': 0.14322478396555247, 'n_estimators': 1346, 'reg_alpha': 3.6472913940516145, 'reg_lambda': 2.197583078109136, 'subsample': 0.40122785264592886, 'colsample_bytree': 0.9061472625392357, 'num_leaves': 77}. Best is trial 21 with value: 0.7092509815747766.\n",
      "[I 2025-04-25 08:22:17,822] Trial 26 finished with value: 0.7035052319268685 and parameters: {'max_depth': 11, 'learning_rate': 0.11141881349085074, 'n_estimators': 1113, 'reg_alpha': 1.0265734125844088, 'reg_lambda': 2.765006037989782, 'subsample': 0.5284239096239325, 'colsample_bytree': 0.832535792352094, 'num_leaves': 62}. Best is trial 21 with value: 0.7092509815747766.\n",
      "[I 2025-04-25 08:22:25,882] Trial 27 finished with value: 0.7033111011044025 and parameters: {'max_depth': 12, 'learning_rate': 0.04441963261684388, 'n_estimators': 1500, 'reg_alpha': 1.9025353517699497, 'reg_lambda': 3.5743000478836593, 'subsample': 0.6953556359463174, 'colsample_bytree': 0.752731491178805, 'num_leaves': 89}. Best is trial 21 with value: 0.7092509815747766.\n",
      "[I 2025-04-25 08:22:27,817] Trial 28 finished with value: 0.7054334836949888 and parameters: {'max_depth': 9, 'learning_rate': 0.16718692186321182, 'n_estimators': 748, 'reg_alpha': 3.0818795330662745, 'reg_lambda': 1.5609929189745273, 'subsample': 0.45001372124841543, 'colsample_bytree': 0.6140698445448807, 'num_leaves': 27}. Best is trial 21 with value: 0.7092509815747766.\n",
      "[I 2025-04-25 08:22:30,107] Trial 29 finished with value: 0.7061113457923667 and parameters: {'max_depth': 10, 'learning_rate': 0.07439045092372046, 'n_estimators': 571, 'reg_alpha': 4.37590867726907, 'reg_lambda': 0.3447427870037002, 'subsample': 0.6313221794780745, 'colsample_bytree': 0.6846804163163202, 'num_leaves': 86}. Best is trial 21 with value: 0.7092509815747766.\n",
      "[I 2025-04-25 08:22:30,109] A new study created in memory with name: no-name-2331c55f-f89a-4324-9088-d99cea456f89\n",
      "[I 2025-04-25 08:22:32,244] Trial 0 finished with value: 0.6863975717986038 and parameters: {'max_depth': 4, 'learning_rate': 0.07227403089516694, 'n_estimators': 861, 'gamma': 1.9197527004150294, 'min_child_weight': 47, 'subsample': 0.7920589610463199, 'colsample_bytree': 0.4166431862999436}. Best is trial 0 with value: 0.6863975717986038.\n",
      "[I 2025-04-25 08:22:33,489] Trial 1 finished with value: 0.6584623600018559 and parameters: {'max_depth': 3, 'learning_rate': 0.012706039585179116, 'n_estimators': 251, 'gamma': 3.5878893790415933, 'min_child_weight': 1, 'subsample': 0.49907427633416457, 'colsample_bytree': 0.6874960007350013}. Best is trial 0 with value: 0.6863975717986038.\n",
      "[I 2025-04-25 08:22:34,056] Trial 2 finished with value: 0.6867280240890028 and parameters: {'max_depth': 4, 'learning_rate': 0.18679915443465564, 'n_estimators': 220, 'gamma': 3.4889211132785842, 'min_child_weight': 19, 'subsample': 0.8488803424846822, 'colsample_bytree': 0.5353107795471685}. Best is trial 2 with value: 0.6867280240890028.\n",
      "[I 2025-04-25 08:22:35,413] Trial 3 finished with value: 0.689219231382293 and parameters: {'max_depth': 9, 'learning_rate': 0.05634815668498006, 'n_estimators': 369, 'gamma': 1.4730857943724303, 'min_child_weight': 44, 'subsample': 0.6060532060588801, 'colsample_bytree': 0.4239916187995495}. Best is trial 3 with value: 0.689219231382293.\n",
      "[I 2025-04-25 08:22:40,415] Trial 4 finished with value: 0.6836350062298249 and parameters: {'max_depth': 3, 'learning_rate': 0.024938842473014308, 'n_estimators': 1294, 'gamma': 3.3585158323976616, 'min_child_weight': 11, 'subsample': 0.4615277879338006, 'colsample_bytree': 0.5696763960447175}. Best is trial 3 with value: 0.689219231382293.\n",
      "[I 2025-04-25 08:22:40,898] Trial 5 finished with value: 0.6855874189956528 and parameters: {'max_depth': 8, 'learning_rate': 0.09195336034322796, 'n_estimators': 124, 'gamma': 2.919633091888314, 'min_child_weight': 22, 'subsample': 0.9647775582109633, 'colsample_bytree': 0.44437347452701415}. Best is trial 3 with value: 0.689219231382293.\n",
      "[I 2025-04-25 08:22:43,239] Trial 6 finished with value: 0.6958606098497992 and parameters: {'max_depth': 9, 'learning_rate': 0.10575931227696768, 'n_estimators': 682, 'gamma': 1.5956953416059698, 'min_child_weight': 46, 'subsample': 0.48911377689359925, 'colsample_bytree': 0.9000748113935545}. Best is trial 6 with value: 0.6958606098497992.\n",
      "[I 2025-04-25 08:22:44,051] Trial 7 finished with value: 0.6894736623538581 and parameters: {'max_depth': 5, 'learning_rate': 0.09896383109775932, 'n_estimators': 124, 'gamma': 0.3509679890759104, 'min_child_weight': 34, 'subsample': 0.6851323827726103, 'colsample_bytree': 0.8923924573797681}. Best is trial 6 with value: 0.6958606098497992.\n",
      "[I 2025-04-25 08:22:47,505] Trial 8 finished with value: 0.6910225138412601 and parameters: {'max_depth': 4, 'learning_rate': 0.04703866785880241, 'n_estimators': 1371, 'gamma': 3.6831555701482133, 'min_child_weight': 7, 'subsample': 0.4873967293628051, 'colsample_bytree': 0.7427165963948531}. Best is trial 6 with value: 0.6958606098497992.\n",
      "[I 2025-04-25 08:22:53,626] Trial 9 finished with value: 0.6908939524661436 and parameters: {'max_depth': 10, 'learning_rate': 0.06819713626582859, 'n_estimators': 1120, 'gamma': 0.42248208912687324, 'min_child_weight': 38, 'subsample': 0.7412600352120168, 'colsample_bytree': 0.80419279096547}. Best is trial 6 with value: 0.6958606098497992.\n",
      "[I 2025-04-25 08:22:55,201] Trial 10 finished with value: 0.6771978282853031 and parameters: {'max_depth': 12, 'learning_rate': 0.14586523415504124, 'n_estimators': 638, 'gamma': 4.8272992356968185, 'min_child_weight': 31, 'subsample': 0.5800556132359089, 'colsample_bytree': 0.9900137122301818}. Best is trial 6 with value: 0.6958606098497992.\n",
      "[I 2025-04-25 08:22:58,642] Trial 11 finished with value: 0.6854107362054456 and parameters: {'max_depth': 6, 'learning_rate': 0.14011367180575385, 'n_estimators': 1478, 'gamma': 4.597632390386609, 'min_child_weight': 1, 'subsample': 0.42062067631194894, 'colsample_bytree': 0.7992975268501377}. Best is trial 6 with value: 0.6958606098497992.\n",
      "[I 2025-04-25 08:23:00,832] Trial 12 finished with value: 0.6977617615112405 and parameters: {'max_depth': 7, 'learning_rate': 0.13031265553002078, 'n_estimators': 817, 'gamma': 2.0389925045569544, 'min_child_weight': 12, 'subsample': 0.5561242880776093, 'colsample_bytree': 0.7315895434120685}. Best is trial 12 with value: 0.6977617615112405.\n",
      "[I 2025-04-25 08:23:03,028] Trial 13 finished with value: 0.698494967300063 and parameters: {'max_depth': 7, 'learning_rate': 0.13364681858542163, 'n_estimators': 730, 'gamma': 1.6123152623195713, 'min_child_weight': 15, 'subsample': 0.6145156675710657, 'colsample_bytree': 0.9293342022561115}. Best is trial 13 with value: 0.698494967300063.\n",
      "[I 2025-04-25 08:23:05,562] Trial 14 finished with value: 0.6942264077187522 and parameters: {'max_depth': 7, 'learning_rate': 0.14268787353737078, 'n_estimators': 930, 'gamma': 2.2900660293871713, 'min_child_weight': 14, 'subsample': 0.6060679897304787, 'colsample_bytree': 0.9934812191703755}. Best is trial 13 with value: 0.698494967300063.\n",
      "[I 2025-04-25 08:23:07,309] Trial 15 finished with value: 0.6972902883398078 and parameters: {'max_depth': 7, 'learning_rate': 0.17487866939345587, 'n_estimators': 478, 'gamma': 0.9640385933460363, 'min_child_weight': 16, 'subsample': 0.6613268762028561, 'colsample_bytree': 0.6408719799485215}. Best is trial 13 with value: 0.698494967300063.\n",
      "[I 2025-04-25 08:23:11,716] Trial 16 finished with value: 0.6968315842971187 and parameters: {'max_depth': 6, 'learning_rate': 0.1218585416414848, 'n_estimators': 1046, 'gamma': 2.579855153630488, 'min_child_weight': 26, 'subsample': 0.5499395661616178, 'colsample_bytree': 0.8798096461598268}. Best is trial 13 with value: 0.698494967300063.\n",
      "[I 2025-04-25 08:23:13,928] Trial 17 finished with value: 0.7048168672453676 and parameters: {'max_depth': 11, 'learning_rate': 0.16832562095595582, 'n_estimators': 702, 'gamma': 1.1092800117405615, 'min_child_weight': 8, 'subsample': 0.743916443983156, 'colsample_bytree': 0.7963215838591582}. Best is trial 17 with value: 0.7048168672453676.\n",
      "[I 2025-04-25 08:23:15,618] Trial 18 finished with value: 0.6966314790727569 and parameters: {'max_depth': 12, 'learning_rate': 0.17007521971399528, 'n_estimators': 578, 'gamma': 0.9369491274111019, 'min_child_weight': 8, 'subsample': 0.8777596411970245, 'colsample_bytree': 0.8068429308877585}. Best is trial 17 with value: 0.7048168672453676.\n",
      "[I 2025-04-25 08:23:17,783] Trial 19 finished with value: 0.694123443145862 and parameters: {'max_depth': 11, 'learning_rate': 0.19666911969056627, 'n_estimators': 701, 'gamma': 1.0234091772263187, 'min_child_weight': 25, 'subsample': 0.7510360698969207, 'colsample_bytree': 0.9315080278178316}. Best is trial 17 with value: 0.7048168672453676.\n",
      "[I 2025-04-25 08:23:19,131] Trial 20 finished with value: 0.6990527372331597 and parameters: {'max_depth': 10, 'learning_rate': 0.16387201383582267, 'n_estimators': 473, 'gamma': 1.3575916260424516, 'min_child_weight': 6, 'subsample': 0.8505615263423765, 'colsample_bytree': 0.835836907764053}. Best is trial 17 with value: 0.7048168672453676.\n",
      "[I 2025-04-25 08:23:20,394] Trial 21 finished with value: 0.7034633000812541 and parameters: {'max_depth': 10, 'learning_rate': 0.1617234244793795, 'n_estimators': 444, 'gamma': 1.4077165783608248, 'min_child_weight': 7, 'subsample': 0.8476132478615023, 'colsample_bytree': 0.8486480265002657}. Best is trial 17 with value: 0.7048168672453676.\n",
      "[I 2025-04-25 08:23:23,591] Trial 22 finished with value: 0.6914965059300738 and parameters: {'max_depth': 10, 'learning_rate': 0.16193856632331846, 'n_estimators': 435, 'gamma': 0.038221308206251026, 'min_child_weight': 6, 'subsample': 0.930235397586076, 'colsample_bytree': 0.8417187755680376}. Best is trial 17 with value: 0.7048168672453676.\n",
      "[I 2025-04-25 08:23:25,087] Trial 23 finished with value: 0.7082828389409292 and parameters: {'max_depth': 11, 'learning_rate': 0.15755481456333822, 'n_estimators': 505, 'gamma': 1.152329583703006, 'min_child_weight': 6, 'subsample': 0.8300707195046221, 'colsample_bytree': 0.7402147272400976}. Best is trial 23 with value: 0.7082828389409292.\n",
      "[I 2025-04-25 08:23:26,847] Trial 24 finished with value: 0.7096982717476136 and parameters: {'max_depth': 11, 'learning_rate': 0.15469696100182326, 'n_estimators': 550, 'gamma': 0.6604279450815658, 'min_child_weight': 3, 'subsample': 0.8117495841571879, 'colsample_bytree': 0.6704061813249935}. Best is trial 24 with value: 0.7096982717476136.\n",
      "[I 2025-04-25 08:23:28,629] Trial 25 finished with value: 0.7138842296654223 and parameters: {'max_depth': 11, 'learning_rate': 0.18493892337147572, 'n_estimators': 607, 'gamma': 0.7241958124096005, 'min_child_weight': 1, 'subsample': 0.7860745715713077, 'colsample_bytree': 0.6667181103700295}. Best is trial 25 with value: 0.7138842296654223.\n",
      "[I 2025-04-25 08:23:30,420] Trial 26 finished with value: 0.7034571000586015 and parameters: {'max_depth': 11, 'learning_rate': 0.18704406080431896, 'n_estimators': 571, 'gamma': 0.5379589067770593, 'min_child_weight': 1, 'subsample': 0.7930132401122653, 'colsample_bytree': 0.6200892068477428}. Best is trial 25 with value: 0.7138842296654223.\n",
      "[I 2025-04-25 08:23:31,522] Trial 27 finished with value: 0.7086029744465736 and parameters: {'max_depth': 12, 'learning_rate': 0.1975184645535801, 'n_estimators': 318, 'gamma': 0.6620568543279792, 'min_child_weight': 3, 'subsample': 0.9011621896536196, 'colsample_bytree': 0.6756642283708357}. Best is trial 25 with value: 0.7138842296654223.\n",
      "[I 2025-04-25 08:23:32,666] Trial 28 finished with value: 0.7034171651945584 and parameters: {'max_depth': 12, 'learning_rate': 0.1962079938466961, 'n_estimators': 329, 'gamma': 0.6615289493265091, 'min_child_weight': 4, 'subsample': 0.9282811618746163, 'colsample_bytree': 0.6641114867943293}. Best is trial 25 with value: 0.7138842296654223.\n",
      "[I 2025-04-25 08:23:36,018] Trial 29 finished with value: 0.7026091557809906 and parameters: {'max_depth': 9, 'learning_rate': 0.18228318575329738, 'n_estimators': 892, 'gamma': 0.05872183802409703, 'min_child_weight': 11, 'subsample': 0.9893286345404794, 'colsample_bytree': 0.580987804163044}. Best is trial 25 with value: 0.7138842296654223.\n"
     ]
    }
   ],
   "source": [
    "# === Optuna Tuning for LightGBM ===\n",
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 100)\n",
    "    }\n",
    "    model = LGBMClassifier(**params)\n",
    "    return cross_val_score(model, X_scaled, y, cv=3, scoring='f1_macro').mean()\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=30)\n",
    "best_lgbm = LGBMClassifier(**study_lgbm.best_params)\n",
    "\n",
    "# === Optuna Tuning for XGB ===\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0)\n",
    "    }\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', **params)\n",
    "    return cross_val_score(model, X_scaled, y, cv=3, scoring='f1_macro').mean()\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "best_xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', **study_xgb.best_params)\n",
    "\n",
    "# === CatBoost (without tuning) ===\n",
    "best_cat = CatBoostClassifier(iterations=1000, depth=6, learning_rate=0.05, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:15:38.786486Z",
     "iopub.status.busy": "2025-04-25T08:15:38.786253Z",
     "iopub.status.idle": "2025-04-25T08:15:38.807772Z",
     "shell.execute_reply": "2025-04-25T08:15:38.806880Z",
     "shell.execute_reply.started": "2025-04-25T08:15:38.786468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Ensemble (ens_1) Metrics ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.79       284\n",
      "           1       0.52      0.43      0.47       159\n",
      "           2       0.81      0.90      0.85       442\n",
      "\n",
      "    accuracy                           0.77       885\n",
      "   macro avg       0.72      0.69      0.70       885\n",
      "weighted avg       0.76      0.77      0.76       885\n",
      "\n",
      "[[214  31  39]\n",
      " [ 35  68  56]\n",
      " [ 12  31 399]]\n"
     ]
    }
   ],
   "source": [
    "# === StratifiedKFold CV with Voting Ensemble ===\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled, y)):\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('lgbm', best_lgbm),\n",
    "            ('xgb', best_xgb),\n",
    "            ('cat', best_cat)\n",
    "        ],\n",
    "        voting='soft'\n",
    "    )\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    preds = ensemble.predict(X_val)\n",
    "    all_preds.extend(preds)\n",
    "    all_true.extend(y_val)\n",
    "    print(f\"Fold {fold+1} Accuracy: {accuracy_score(y_val, preds):.4f}\")\n",
    "\n",
    "# === Final Evaluation ===\n",
    "print(\"\\n=== Overall Performance ===\")\n",
    "print(classification_report(all_true, all_preds))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 4865789,
     "datasetId": 2780494,
     "sourceId": 4802354,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
